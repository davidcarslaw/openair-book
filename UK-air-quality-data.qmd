---
author: David Carslaw
editor_options: 
  markdown: 
    wrap: 72
abstract: This section outlines the different ways users can access the abundant air quality data in the UK. The main functions provide easy access to hourly data and other statistical summaries such as annual means and data capture rates. Easy access is also provided to site meta data such as longitude, latitude, site type and details of the pollutants measured.
---

# Accessing UK Air Quality Data {#sec-importAURN}

## Accessing data

The UK has a surprisingly large amount of air quality data that is
publicly accessible. The main UK AURN archive and regional (England,
Scotland, Wales and Northern Ireland) together with Imperial College
London's London Air Quality Network (LAQN) are important and large
databases of information that allow free public access. Storing and
managing data in this way has many advantages including consistent data
format, and underlying high quality methods to process and store the
data.

[openair]{.pkg} has a family of functions that provide users with
extensive access to UK air quality data. Ricardo Energy & Environment
have provided .RData files (R workspaces) for several important air
quality networks in the UK. These files are updated on a daily basis.
This approach requires a link to the Internet to work. The work of
Trevor Davies at Ricardo Energy & Environment is greatly appreciated in
making all the data available. The networks include:

-   `importAURN` For importing data from the UK national network called
    [Automatic Urban and Rural
    Network](https://uk-air.defra.gov.uk/networks/network-info?view=aurn).
    This is the main UK network.

-   `importSAQN` For accessing data from [Air Quality
    Scotland](http://www.scottishairquality.scot/) network.

-   `importWAQN` For accessing data from the [Air Quality
    Wales](https://airquality.gov.wales/) network.

-   `importAQE` For accessing data from the [Air Quality
    England](https://www.airqualityengland.co.uk/) network of sites.

-   `importNI` For accessing data from the [Northern
    Ireland](https://www.airqualityni.co.uk) network of sites.

-   `importLocal` Import data from locally managed AQ networks in
    England. These are sites operated in most cases by Local Authorities
    but may also include monitoring from other programmes, industry and
    airports. The location and purpose of these sites differs from the
    national network which is governed by strict rules of the air
    quality directives. As a result there is a broad range of site
    types, equipment and data quality practices. For more information
    see
    [here](https://uk-air.defra.gov.uk/networks/network-info?view=nondefraaqmon).
    These data represent information from about 15 different local air
    quality networks.

-   `importEurope` A simplified version of a function to give basic
    access to hourly European data based on Stuart Grange's
    [saqgetr]{.pkg} package --- see
    <https://github.com/skgrange/saqgetr>. The [openair]{.pkg} function
    has a similar approach to other [openair]{.pkg} import functions
    i.e. requires a site code(s) and year(s) to be supplied.

-   `importKCL` For accessing data from the sites operated by Imperial
    College London[^uk-air-quality-data-1], primarily including the [The
    London Air Quality
    Network](https://www.londonair.org.uk/LondonAir/Default.aspx).

[^uk-air-quality-data-1]: The data were first accessible when the
    Environmental Research Group was based at King's College London.

Many users download hourly data from the air quality archive at
<https://www.airquality.co.uk>. Most commonly, the data are emailed to
the user as .csv files and have a fixed format as shown below. This is a
useful facility but does have some limitations and frustrations, many of
which have been overcome using a new way of storing and downloading the
data described below.

There are several advantages over the web portal approach where .csv
files are downloaded. First, it is quick to select a range of sites,
pollutants and periods (see examples below). Second, storing the data as
.RData objects is very efficient as they are about four times smaller
than .csv files (which are already small) --- which means the data
downloads quickly and saves bandwidth. Third, the function completely
avoids any need for data manipulation or setting time formats, time
zones etc. Finally, it is easy to import many years of data. The final
point makes it possible to download several long time series in one go.

The site codes and pollutant names can be upper or lower case.

Some examples of usage are shown below. First load the packages we need.

```{r}
#| warning: false
#| message: false
#| cache: false
library(openair)
library(tidyverse)
```

## Site Meta Data

### National networks

The first question is, what sites are available and what do they
measure? Users can access the details of air pollution monitoring sites
using the `importMeta` function. The user only needs to provide the
network name and (optionally) whether all data should be returned and
whether certain periods should be considered. By default only site type,
latitude and longitude are returned.

```{r}
#| label: importMeta
#| warning: false
#| message: false
aurn_meta <- importMeta(source = "aurn")
aurn_meta
```

Or return much more detailed data that includes which pollutants are
measured at each site and site start / end dates. The option
`all = TRUE` should be added.

```{r}
#| label: importMetaAll
#| eval: true
aurn_meta <- importMeta(source = "aurn", all = TRUE) 

# what comes back?
glimpse(aurn_meta)
```

Note that `importMeta` can import information for several networks at
once e.g. `source = c("aurn", "saqn")`.

Often it is useful to consider sites that were open in a particular year
or were open for a duration of years. This can be done using the `year`
argument. When `year` is a range such as `year = 2010:2020`, only sites
that were open across that range of years will be returned. This option
is especially useful for trend analysis when there might be an interest
in extracting only sites that were measuring over the period of
interest. Furthermore, if `all = TRUE` is used, supplying a year (or
years) will select only specific pollutants that were measured during
the period of interest.[^uk-air-quality-data-2]

[^uk-air-quality-data-2]: Note that while a site may have been in
    operation for a long time, it is not necessarily the case that all
    pollutants were measured since the start of the site.

For example, to check the number of sites that were open from 2010 to
2022 in the AURN and SAQN combined:

```{r}
sites_2010_2022 <- importMeta(
  source = c("aurn", "saqn"),
  year = 2010:2022
)

nrow(sites_2010_2022)
```

The example below uses sites on the AURN that measure NO~2~, but can
easily be extended to the other data sources.

To see how many sites measure NO~2~ in the AURN that are 'urban
traffic':

```{r}
#| warning: false
#| message: false
aurn_detailed <- importMeta(source = "aurn", all = TRUE)

no2_sites <- filter(
  aurn_detailed,
  variable == "NO2",
  site_type == "Urban Traffic"
)

nrow(no2_sites)
```

::: callout-tip
## Use `importMeta` as a way to select sites to import

One of the most useful aspects of `importMeta` is to use it as a basis
to identify site codes to then import data. For example, to import data
from the AURN for sites that have been in operation from 2005 to 2020:

```{r}
#| eval: false
sites_2005_2020 <- importMeta(
  source = "aurn",
  year = 2005:2020
)

all_aq_data <- importAURN(
  site = sites_2005_2020$code,
  year = 2005:2020
)
```
:::

To import data, you can use the different versions of `importAURN`. Some
examples are below.

```{r}
#| eval: false
## import all pollutants from Marylebone Rd from 2000:2005
mary <- importAURN(site = "my1", year = 2000:2005)

## import nox, no2, o3 from Marylebone Road and Nottingham Centre for 2000
thedata <- importAURN(site = c("my1", "nott"), year = 2000,
                      pollutant = c("nox", "no2", "o3"))

## import over 30 years of Mace Head O3 data!
o3 <- importAURN(site = "mh", year = 1987:2019)

## import hydrocarbon data from Marylebone Road
hc <- importAURN(site = "my1", year = 2008, hc = TRUE)

## Import data from the AQE network (York data in this case)
yk13 <- importAQE(site = "yk13", year = 2018)
```

And to include basic meta data when importing air pollution data:

```{r}
#| label: importWithMeta
kc1 <- importAURN(site = "kc1", year = 2018, meta = TRUE)

glimpse(kc1)
```

By default, the function returns data where each pollutant is in a
separate column. However, it is possible to return the data in a *tidy*
format (column for pollutant name, column for value) by using the option
`to_narrow`:

```{r}
#| eval: false
my1 <- importAURN("my1", year = 2018, to_narrow = TRUE)
```

It is also possible to return information on whether the data have been
ratified or not using the option `ratified` (`FALSE` by default). So,
add the option `ratified = TRUE` if you want this information.

### Local networks

In the case of **locally available data**, it is useful to know who the
data providers are, which are shown below.

```{r}
# access local meta data to get provider
meta_local <- importMeta("local", all = TRUE)
unique(meta_local$provider)
```

## Plot Sites on a Map

To easily visualise entire monitoring networks, consider using the
[openairmaps]{.pkg} R package. This package can be installed from CRAN,
similar to [openair]{.pkg}.

```{r}
#| eval: false
install.packages("openairmaps")
```

This package contains the `networkMap` function which acts as a wrapper
around `importMeta` and returns a detailed map similar to the one
produced above, with many options for customisation. For example, sites
can be clustered together to avoid clutter, and an optional "control
menu" can be added to filter for certain sites (e.g., different site
types, shown below).

```{r}
#| label: fig-openairmapsNetworkMap
#| cache: false
#| fig-cap: Plotting the AURN using the `openairmaps` package.
#| results: asis
library(openairmaps)
networkMap(source = "aurn", control = "site_type")
```

For more information about using [openairmaps]{.pkg} to build maps of
monitoring networks, please refer to the [Network Visualisation
Page](maps-network.qmd).

## Annual and other statistics

By default, all the functions above return hourly data. However, often
there is a need to return data such as annual means of a long period of
time. The UK family of functions (but not `importKCL`) can return data
for averaging times: annual, monthly, daily and for SO~2~ 15-minute. The
annual and monthly data also provide valuable information on data
capture rates. The averaging statistic is selected with the `data_type`
option. The values `data_type` can take include:

-   **"hourly"** This is the default and specific site(s) must be
    provided.
-   **"daily"** Daily means returned and specific site(s) must be
    provided. Note that in the case of PM~10~ and PM~2.5~ daily
    measurements can be available from those derived from hourly
    measurements (using instruments such as TEOM, BAM and FIDAS) our
    daily gravimetric measurements such as from a Partisol. In the
    returned data the gravimetric daily measurements are shown as
    `gr_pm10` and `gr_pm2.5`, respectively.
-   **"monthly"** Monthly means returned. No site code is needed because
    all data for a particular year are returned. Data capture statistics
    are also given.
-   **"annual"** Annual means returned. No site code is needed because
    all data for a particular year are returned. Data capture statistics
    are also given.
-   **"15_min"** 15-minute SO~2~ concentrations returned for a specific
    site(s).
-   **"8_hour"** Rolling 8-hour concentrations returned for a specific
    site(s) for O~3~ and CO.
-   **"24_hour"** Rolling 24-hour concentrations returned for a specific
    site(s) for PM~10~ and PM~2.5~.
-   **"daily_max_8"** Maximum daily rolling 8-hour maximum for O~3~ and
    CO.
-   **"daqi"** Daily Air Quality Index (DAQI). See
    [here](https://uk-air.defra.gov.uk/air-pollution/daqi?view=more-info&pollutant=ozone#pollutant)
    for more details of how the index is defined.

Note that for annual and monthly statistics all network data is returned
and the `site` option has no effect.

As an example, to import 5 years of annual mean data from the AURN:

```{r}
#| eval: false
uk_annual <- importAURN(year = 2016:2020, data_type = "annual")
```

By default, this will return data in "wide" format with a pollutant and
its data capture rate in separate columns. Often it is more useful to
have "narrow" format data, which is possible to select with the
`to_narrow` option. Furthermore, it is also possible to return site meta
data (site type, latitude and longitude) at the same time.

Below is an example of obtaining annual mean data for 2020.

```{r}
#| label: importAnnual
uk_2020 <- importAURN(
  year = 2020,
  data_type = "annual",
  meta = TRUE,
  to_narrow = TRUE
)

uk_2020
```

The pollutants returned include:

```{r}
unique(uk_2020$species)
```

Now it is easy for example, to select annual mean data from 2020 for
NO~2~ with a data capture rate of at least 80%:

```{r}
#| label: filterNO2
uk_2020 %>%
  filter(species == "no2", data_capture >= 0.8)
```

For the AURN, it is also possible to return the DAQI (Daily Air Quality
Index) by pollutant to save deriving it.

```{r}
#| label: daqi
daqi_2020 <- importAURN(
  year = 2020,
  data_type = "daqi", meta = TRUE
)

daqi_2020
```
