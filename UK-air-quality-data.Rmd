# (PART) Data access {-}

# Accessing UK Air Quality Data {#importAURN}

The UK has a surprisingly large amount of air quality data that is publicly accessible. The main UK AURN archive and regional (England, Scotland, Wales and Northern Ireland) together with
Imperial College London's London Air Quality Network (LAQN) are 
important and large databases of information that allow free public
access. Storing and managing data in this way has many advantages
including consistent data format, and underlying high quality methods
to process and store the data.

## Accessing data

[openair]{.pkg} has a family of functions that provide users with extensive
access to UK air quality data. Ricardo Energy \& Environment have
provided .RData files (R workspaces) for several important air quality
networks in the UK. These files are updated on a daily basis. This
approach requires a link to the Internet to work. The networks include:

-  `importAURN` For importing data from the UK national
  network called
  [Automatic Urban and Rural Network}](https://uk-air.defra.gov.uk/networks/network-info?view=aurn). This is the main UK network.
  
- `importSAQN` For accessing data from
  [Air Quality Scotland](http://www.scottishairquality.scot/)
  network.  
  
-  `importWAQN` For accessing data from the
  [Air Quality Wales](https://airquality.gov.wales/) network. 
  
-  `importAQE` For accessing data from the
  [Air Quality England](https://www.airqualityengland.co.uk/)
  network of sites. 

-  `importNI` For accessing data from the
  [Northern Ireland](https://www.airqualityni.co.uk)
  network of sites. 

- `importEurope` A simplified version of a function to give
  basic access to hourly European data based on Stuart Grange's
  \cd{saqgetr} package --- see
  https://github.com/skgrange/saqgetr. The [openair]{.pkg} function has
  a similar approach to other [openair]{.pkg} import functions i.e. requires
  a site code(s) and year(s) to be supplied.
  
-  `importKCL` For accessing data from the sites operated by
  King's College London, primarily including the
  [The London Air Quality Network](https://www.londonair.org.uk/LondonAir/Default.aspx). 


Many users download hourly data from the air quality archive at
http://www.airquality.co.uk. Most commonly, the data are emailed
to the user as .csv files and have a fixed format as shown below. This
is a useful facility but does have some limitations and frustrations,
many of which have been overcome using a new way of storing and
downloading the data described below.

There are several advantages over the web portal approach where .csv
files are downloaded. First, it is quick to select a range of sites,
pollutants and periods (see examples below). Second, storing the data
as .RData objects is very efficient as they are about four times
smaller than .csv files (which are already small) --- which means the
data downloads quickly and saves bandwidth. Third, the function
completely avoids any need for data manipulation or setting time
formats, time zones etc. Finally, it is easy to import many years of
data. The final point makes it possible to download several long time
series in one go.

The site codes and pollutant names can be upper or lower case. 

Some examples of usage are shown below. First load the packages we need.

```{r warning=FALSE,message=FALSE,cache=FALSE}
library(openair)
library(tidyverse)
```

## Site Meta Data

The first question is, what sites are available and what do they measure? Users can access the details of air pollution monitoring sites using
the `importMeta` function. The user only needs to provide the
network name and (optionally) whether all data should be returned. By
default only site type, latitude and longitude are returned.

```{r importMeta,warning=FALSE,message=FALSE}
aurn_meta <- importMeta(source = "aurn")
aurn_meta
```

Or return much more detailed data that includes which pollutants are measured at each site and site start / end dates. The option `all = TRUE` should be added.

```{r importMetaAll,eval=FALSE}
aurn_meta <- importMeta(source = "aurn", all = TRUE) 
aurn_meta
```

The example below uses sites on the AURN that measure NO~2~, but can easily be extended to the other data sources.

To see how many sites measure NO~2~ in the AURN that are 'urban traffic':
```{r warning=FALSE,message=FALSE}
aurn_detailed <- importMeta(source = "aurn", all = TRUE)

no2_sites <- filter(
  aurn_detailed,
  variable == "NO2",
  site_type == "Urban Traffic"
)

nrow(no2_sites)
```

To import data, you can use the different versions of `importAURN`. Some examples are below.

```{r eval=FALSE}
## import all pollutants from Marylebone Rd from 2000:2005
mary <- importAURN(site = "my1", year = 2000:2005)

## import nox, no2, o3 from Marylebone Road and Nottingham Centre for 2000
thedata <- importAURN(site = c("my1", "nott"), year = 2000,
                      pollutant = c("nox", "no2", "o3"))

## import over 30 years of Mace Head O3 data!
o3 <- importAURN(site = "mh", year = 1987:2019)
## import hydrocarbon data from Marylebone Road
hc <- importAURN(site = "my1", year = 2008, hc = TRUE)

## Import data from the AQE network (York data in this case)
yk13 <- importAQE(site = "yk13", year = 2018)
```

And to include basic meta data when importing air pollution data:

```{r importWithMeta}
kc1 <- importAURN(site = "kc1", year = 2018, meta = TRUE)

glimpse(kc1)
``` 

The latter is useful if you then want to plot the sites on a map, as shown below.

By default, the function returns data where each pollutant is in a
separate column. However, it is possible to return the data in a
*tidy* format (column for pollutant name, column for value) by
using the option `to_narrow`:

```{r eval=FALSE}
my1 <- importAURN("my1", year = 2018, to_narrow = TRUE)
``` 

It is also possible to return information on whether the data have been ratified or not using the option `ratified` (`FALSE` by default). So, add the option `ratified = TRUE` if you want this information.

## Plot Sites on a Map

In the example below the unique sites are selected from
`aurn_detailed` because the `site` repeats the number of pollutants
that are measured. Information is also collected for the map popups
and then the map is plotted.

```{r}
library(leaflet)

aurn_unique <- distinct(aurn_detailed, site, .keep_all = TRUE)

# information for map markers
content <- paste(
  paste(
    aurn_unique$site,
    paste("Code:", aurn_unique$code),
    paste("Start:", aurn_unique$start_date),
    paste("End:", aurn_unique$end_date),
    paste("Site Type:", aurn_unique$site_type),
    sep = "<br/>"
  )
)


# plot map
leaflet(aurn_unique) %>%
  addTiles() %>%
  addMarkers(~ longitude, ~ latitude, popup = content,
             clusterOptions = markerClusterOptions())
```

## Annual and other statistics

By default, all the functions above return hourly data. However, often there is a need to return data such as annual means of a long period of time. The UK family of functions (but not `importKCL`) can return data for averaging times: annual, monthly, daily and for SO~2~ 15-minute. The annual and monthly data also provide valuable information on data capture rates. The averaging statistic is selected with the `data_type` option. The values `data_type` can take include:

- **"hourly"** This is the default and specific site(s) must be provided.
- **"daily"** Daily means returned and specific site(s) must be provided.
- **"monthly"** Monthly means returned. No site code is needed because all data for a particular year are returned. Data capture statistics are also given.
- **"annual"** Annual means returned. No site code is needed because all data for a particular year are returned. Data capture statistics are also given.
- **"15min"** 15-minute SO~2~ concentrations returned for a specific site(s).

Note that for annual and monthly statistics all network data is returned and the `site` option has no effect.

As an example, to import 5 years of annual mean data from the AURN:

```{r eval=FALSE}
uk_annual <- importAURN(year = 2016:2020, data_type = "annual")
```

By default, this will return data in "wide" format with a pollutant and its data capture rate in separate columns. Often it is more useful to have "narrow" format data, which is possible to select with the `to_narrow` option. Furthermore, it is also possible to return site meta data (site type, latitude and longitude) at the same time. 

Below is an example of obtaining annual mean data for 2020.

```{r importAnnual}
uk_2020 <- importAURN(year = 2020, 
                      data_type = "annual",
                      meta = TRUE,
                      to_narrow = TRUE)

uk_2020
```

The pollutants returned include:

```{r}
unique(uk_2020$species)
```

Now it is easy for example, to select annual mean data from 2020 for NO~2~ with a data capture rate of at least 80%:

```{r filterNO2}
uk_2020 %>% 
  filter(species == "no2", data_capture >= 0.8)
```

